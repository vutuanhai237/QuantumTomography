{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init\n",
    "from base import epsilon_rho, metrics\n",
    "from base import optimize_algorithm as optimize\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.linalg import eigh\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j],\n",
       "         [ 0.        +0.j,  1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.        +0.j,  0.        +0.j,  1.        +0.j,\n",
       "           0.        +0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j],\n",
       "         [-0.        +0.j        ,  1.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [-0.        +0.j        ,  0.        +0.j        ,\n",
       "           1.        +0.j        ,  0.        +0.j        ]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j],\n",
       "         [ 0.        +0.j, -1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j],\n",
       "         [-0.        +0.j,  0.        +0.j,  1.        +0.j,\n",
       "           0.        +0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.j        ,  0.        +1.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j],\n",
       "         [-0.        +0.j        ,  0.        +0.j        ,\n",
       "           1.        +0.j        ,  0.        +0.j        ]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j],\n",
       "         [ 0.        +0.j,  0.        +0.j, -1.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.        +0.j,  1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.j        ,  0.        +0.j        ,\n",
       "           0.        +1.j        ,  0.        +0.j        ],\n",
       "         [ 0.        +0.j        ,  1.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[ 0.        +0.j,  1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j],\n",
       "         [ 0.        +0.j,  0.        +0.j,  1.        +0.j,\n",
       "           0.        +0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.        +0.j        ,  1.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j],\n",
       "         [-0.        +0.j        ,  0.        +0.j        ,\n",
       "           1.        +0.j        ,  0.        +0.j        ]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.        +0.j,  1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j],\n",
       "         [ 0.        +0.j,  0.        +0.j, -1.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "          -0.70710678+0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.        +0.j        ,  1.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.j        ,  0.        +0.j        ,\n",
       "           0.        +1.j        ,  0.        +0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[ 0.        +0.j,  0.        +0.j,  1.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [ 0.        +0.j,  1.        +0.j,  0.        +0.j,\n",
       "           0.        +0.j],\n",
       "         [-0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j],\n",
       "         [ 0.70710678+0.j,  0.        +0.j,  0.        +0.j,\n",
       "           0.70710678+0.j]])),\n",
       " (array([-1.,  0.,  0.,  1.]),\n",
       "  array([[-0.        +0.j        ,  0.        +0.j        ,\n",
       "           1.        +0.j        ,  0.        +0.j        ],\n",
       "         [-0.        +0.j        ,  1.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        +0.j        ],\n",
       "         [-0.70710678+0.j        ,  0.        +0.j        ,\n",
       "           0.        +0.j        , -0.70710678+0.j        ],\n",
       "         [ 0.        +0.70710678j,  0.        +0.j        ,\n",
       "           0.        +0.j        ,  0.        -0.70710678j]])),\n",
       " (array([-0.70710678,  0.        ,  0.        ,  0.70710678]),\n",
       "  array([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
       "         [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])),\n",
       " (array([-0.81649658,  0.        ,  0.40824829,  0.40824829]),\n",
       "  array([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
       "         [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])),\n",
       " (array([-0.8660254 ,  0.28867513,  0.28867513,  0.28867513]),\n",
       "  array([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
       "         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
       "         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
       "         [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gellmann_matrices(d):\n",
    "    \"\"\"Generate generalized Gell-Mann matrices for SU(d).\"\"\"\n",
    "    matrices = []\n",
    "    \n",
    "    # Off-diagonal symmetric and anti-symmetric\n",
    "    for i in range(d):\n",
    "        for j in range(i + 1, d):\n",
    "            mat = np.zeros((d, d), dtype=complex)\n",
    "            mat[i, j] = mat[j, i] = 1\n",
    "            matrices.append(mat)\n",
    "\n",
    "            mat = np.zeros((d, d), dtype=complex)\n",
    "            mat[i, j] = -1j\n",
    "            mat[j, i] = 1j\n",
    "            matrices.append(mat)\n",
    "\n",
    "    # Diagonal traceless matrices\n",
    "    for k in range(1, d):\n",
    "        diag_matrix = np.zeros((d, d), dtype=complex)\n",
    "        for i in range(k):\n",
    "            diag_matrix[i, i] = 1\n",
    "        diag_matrix[k, k] = -k\n",
    "        matrices.append(diag_matrix / np.sqrt(k * (k + 1)))\n",
    "\n",
    "    return matrices\n",
    "\n",
    "def diagonalize_gellmann(d):\n",
    "    \"\"\"Diagonalize the Gell-Mann matrices for SU(d).\"\"\"\n",
    "    lambdas = gellmann_matrices(d)\n",
    "    eigen_data = []\n",
    "\n",
    "    for l in lambdas:\n",
    "        eigvals, eigvecs = np.linalg.eigh(l) \n",
    "        eigen_data.append((eigvals, eigvecs)) \n",
    "    \n",
    "    return eigen_data\n",
    "\n",
    "diagonalize_gellmann(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def construct_measurement_operators():\n",
    "    eigen_data = diagonalize_gellmann(2)\n",
    "    projectors = []\n",
    "\n",
    "    for _, eigenvectors in eigen_data:\n",
    "        for i in range(eigenvectors.shape[1]):  # Each eigenstate\n",
    "            vi = eigenvectors[:, i].reshape(-1, 1)  # |v_i⟩\n",
    "            projector = vi @ vi.conj().T  # |v_i⟩⟨v_i|\n",
    "            projectors.append(projector)\n",
    "    # Ensure they sum to identity\n",
    "    sum_projectors = sum(projectors)\n",
    "    scale_factor = np.trace(sum_projectors) / np.trace(np.eye(2))  # Normalize to identity\n",
    "    projectors = [M / scale_factor for M in projectors]\n",
    "\n",
    "    return projectors\n",
    "\n",
    "def generate_n_qubits_measurement_operators(n):\n",
    "    single_qubit_M = construct_measurement_operators()\n",
    "    M_n_qubit = []\n",
    "\n",
    "    for combination in itertools.product(single_qubit_M, repeat=n):\n",
    "        M = combination[0]\n",
    "        for i in range(1, n):\n",
    "            M = np.kron(M, combination[i])  # Extend to n-qubit\n",
    "        M_n_qubit.append(M)\n",
    "        \n",
    "\n",
    "    return M_n_qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_n_qubits_rho(n):\n",
    "    \"\"\"Generate 6^n probe states for an n-qubit system.\"\"\"\n",
    "    d = 2**n \n",
    "    eigen_data = diagonalize_gellmann(d)\n",
    "    \n",
    "    # Extract eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = zip(*eigen_data)\n",
    "    eigvals = np.abs(eigvals)\n",
    "    eigvals /= np.sum(eigvals)\n",
    "    rho_list = []\n",
    "\n",
    "    for _ in range(6**n):\n",
    "        eig_set = random.choice(eigvals)  # Sample eigenvalues\n",
    "        eig_diag = np.diag(eig_set) \n",
    "\n",
    "        eig_vec = eigvecs[0]\n",
    "        rho = eig_vec @ eig_diag @ eig_vec.conj().T \n",
    "        rho /= np.trace(rho)  # Normalize\n",
    "\n",
    "        rho_list.append(rho)\n",
    "\n",
    "    return rho_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 36 of (4, 4) rho.\n",
      "Generated 36 of (4, 4) M.\n",
      "Generated (4, 4) epsilon.\n",
      "Generated 4 of (4, 4) kraus operators.\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "\n",
    "# Generate 6^n density matrices\n",
    "rho_list = generate_n_qubits_rho(n)\n",
    "print(f\"Generated {len(rho_list)} of {rho_list[0].shape} rho.\")\n",
    "\n",
    "# Generate 6^n measurement operators\n",
    "M_list = generate_n_qubits_measurement_operators(n)\n",
    "print(f\"Generated {len(M_list)} of {M_list[0].shape} M.\")\n",
    "\n",
    "# Generate epsilon\n",
    "epsilon = init.create_unitary_matrix(num_qubits=n)\n",
    "print(f\"Generated {epsilon.shape} epsilon.\")\n",
    "\n",
    "# Generate K list\n",
    "unitary = init.create_unitary_matrix(num_qubits=n)\n",
    "kraus_operators = init.create_kraus_operators_from_unitary(unitary)\n",
    "print(f\"Generated {len(kraus_operators)} of {kraus_operators[0].shape} kraus operators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d_{i,j}):\n",
      " (36, 36)\n"
     ]
    }
   ],
   "source": [
    "def compute_simulated_data(M_list, rho_list, epsilon):\n",
    "    \"\"\"Compute d_{i,j} = Tr(M_j E_rand(rho_i))\"\"\"\n",
    "\n",
    "    data = np.zeros((len(rho_list), len(M_list)), dtype=complex)\n",
    "    \n",
    "    for i, rho in enumerate(rho_list):\n",
    "        rho_transformed = epsilon_rho.calculate_from_unitary(rho=rho, unitary_matrix=epsilon)  # Apply channel\n",
    "        for j, M in enumerate(M_list):\n",
    "            data[i, j] = np.trace(M @ rho_transformed)  # Compute expectation value\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Compute and print the simulated data\n",
    "simulated_data = compute_simulated_data(M_list, rho_list, epsilon)\n",
    "print(\"(d_{i,j}):\\n\", simulated_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: tf.Tensor(0.17783323225306555, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def loss_function(d_ij, M_list, rho_list, kraus_operators):\n",
    "    \"\"\"Compute loss = Σ (d_{i,j} - Tr(M_j * E(rho_i)))^2\"\"\"\n",
    "    \n",
    "    loss = tf.constant(0.0, dtype=tf.complex128)  # Initialize loss\n",
    "    \n",
    "    for i, rho in enumerate(rho_list):\n",
    "        rho_transformed = epsilon_rho.calculate_from_kraus_operators(\n",
    "            rho=rho, kraus_operators=kraus_operators\n",
    "        )  # Apply channel\n",
    "        \n",
    "        for j, M in enumerate(M_list): \n",
    "            predicted = tf.linalg.trace(tf.linalg.matmul(M, rho_transformed))  # Tr( M_j * rho_i' )\n",
    "            diff = d_ij[i, j] - predicted\n",
    "            loss += diff ** 2  # Squared absolute error\n",
    "    \n",
    "    return tf.math.real(loss)\n",
    "loss_value = loss_function(simulated_data, M_list, rho_list, kraus_operators)\n",
    "\n",
    "print(\"Loss function value:\", loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_adam_kraus(M_list, rho_list, unitary, kraus_operators, m, v, num_qubits, t, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, mode = 'fidelity'):\n",
    "    tensorKraus = tf.Variable(kraus_operators, dtype=tf.complex128)\n",
    "\n",
    "    beta1 = tf.constant(beta1, dtype=tf.complex128)\n",
    "    beta2 = tf.constant(beta2, dtype=tf.complex128)\n",
    "    t = tf.constant(t, dtype=tf.complex128)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        data = compute_simulated_data(M_list, rho_list, unitary)\n",
    "        f = loss_function(data, M_list, rho_list, tensorKraus)\n",
    "    \n",
    "    # Calculate the gradient\n",
    "    c = tape.gradient(f, tensorKraus)\n",
    "    \n",
    "    # Calculate projection\n",
    "    proj = c - tensorKraus @ (np.transpose(np.conjugate(c)) @ tensorKraus + np.transpose(np.conjugate(tensorKraus)) @ c) / 2\n",
    "\n",
    "    # Update Adam variables\n",
    "    m = beta1 * m + (1 - beta1) * proj\n",
    "    v = beta2 * v + (1 - beta2) * tf.math.square(proj)\n",
    "\n",
    "    # Bias correction\n",
    "    m_hat = m / (1 - tf.pow(beta1, t + 1))\n",
    "    v_hat = v / (1 - tf.pow(beta2, t + 1))\n",
    "\n",
    "    # Update the Kraus operators using Adam update rule\n",
    "    updated_kraus_operators = tensorKraus - alpha * m_hat / (tf.math.sqrt(v_hat) + epsilon)\n",
    "    return updated_kraus_operators, m, v, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_adam_kraus(M_list, rho_list, unitary, kraus_operators, num_qubits, alpha=0.001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, num_loop=1000):\n",
    "    kraus_operators_copy = tf.identity(kraus_operators)\n",
    "    \n",
    "    # Initialize m, v to zero matrices\n",
    "    m = tf.zeros_like(kraus_operators_copy, dtype=tf.complex128)\n",
    "    v = tf.zeros_like(kraus_operators_copy, dtype=tf.complex128)\n",
    "    \n",
    "    # Initialize a dictionary to track cost at each iteration\n",
    "    cost_dict = []\n",
    "\n",
    "    # Try looping manually\n",
    "    for i in range(num_loop):\n",
    "        kraus_operators_copy, m, v, cost = calculate_adam_kraus(M_list, rho_list, unitary, kraus_operators_copy, m = m, v = v, num_qubits=num_qubits, t = i, alpha=alpha, beta1=beta1, beta2=beta2, epsilon=epsilon)\n",
    "        print(cost)\n",
    "        \n",
    "        \n",
    "        # Store the cost for this iteration\n",
    "        cost_dict.append(cost.numpy().real)\n",
    "        \n",
    "        # Reshape the matrices\n",
    "        kraus_operators_copy = renormalize_kraus(kraus_operators_copy)\n",
    "        check_kraus_validity(kraus_operators_copy)\n",
    "        m = tf.reshape(m, (2**num_qubits, 2**num_qubits, 2**num_qubits))\n",
    "        v = tf.reshape(v, (2**num_qubits, 2**num_qubits, 2**num_qubits))\n",
    "\n",
    "    return kraus_operators_copy, cost_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.17783323225306555, shape=(), dtype=float64)\n",
      "tf.Tensor(0.09305786270296945, shape=(), dtype=float64)\n",
      "tf.Tensor(0.050310479091792634, shape=(), dtype=float64)\n",
      "tf.Tensor(0.032338175607970567, shape=(), dtype=float64)\n",
      "tf.Tensor(0.024975155813595898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.020208018707909663, shape=(), dtype=float64)\n",
      "tf.Tensor(0.015199864816154285, shape=(), dtype=float64)\n",
      "tf.Tensor(0.010384734742317174, shape=(), dtype=float64)\n",
      "tf.Tensor(0.006995008541114377, shape=(), dtype=float64)\n",
      "tf.Tensor(0.005480342717166463, shape=(), dtype=float64)\n",
      "tf.Tensor(0.005087266526334199, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0048865623346148876, shape=(), dtype=float64)\n",
      "tf.Tensor(0.004579572056489723, shape=(), dtype=float64)\n",
      "tf.Tensor(0.004245657580634725, shape=(), dtype=float64)\n",
      "tf.Tensor(0.003947091609232722, shape=(), dtype=float64)\n",
      "tf.Tensor(0.003621485302697546, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0032214604717145734, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0028137271043520745, shape=(), dtype=float64)\n",
      "tf.Tensor(0.002482282742984292, shape=(), dtype=float64)\n",
      "tf.Tensor(0.002177759684788412, shape=(), dtype=float64)\n",
      "tf.Tensor(0.001812442364266464, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0014152495602674615, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0010931594888187698, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0008889216660492382, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000789703352234285, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0008371150108296539, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0010607330473599577, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0013134220719874402, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0013567640563656586, shape=(), dtype=float64)\n",
      "tf.Tensor(0.001120673543963126, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007669977087084954, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005343144429079767, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005675587813332806, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0008439861469673014, shape=(), dtype=float64)\n",
      "tf.Tensor(0.001187520861400931, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0013717765554188315, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0012825578002690638, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009865374466680962, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000650060988129145, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00041817064153379613, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0003479493318983939, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000409184536811958, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005202777012023018, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005912848244535353, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005708806352095707, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004756755161741914, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00036471993024613425, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002835809220029907, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00024283222153988657, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023600964599557764, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00024945765770773134, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002599766400559823, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00025118177827541927, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023203468872861453, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00022363187592888383, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023304725551589157, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002488266818258224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002541308010417205, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023931910142749402, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00020960434404991942, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00018438065066713196, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0001851827546541513, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002203723099770827, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00027633156759495145, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00032051240571765127, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00032050086832423276, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002704202288768113, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00020109076156248575, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0001624505913442639, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0001912366646807776, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002846291953354646, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00039801024081015645, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00047330399006173616, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004768843672539623, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000417038625118048, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00033469460438282196, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00027930977787385294, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002824754350557848, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0003424285369877239, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004300143793803607, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000508912453729227, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005503402734773515, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005367861192597353, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00046533706639255033, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0003546743601785119, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00024802476283283917, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00020231561849648466, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000259966552366367, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00041646768461607944, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0006109624528040249, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007537828615943203, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007741968993616988, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0006576694980265697, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00045441133117078497, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002600060725504991, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00017597617578431503, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00026007159715253484, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004876125507023356, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007539573725378224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009264433652750285, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009144354706487008, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007160139833137524, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00042318721849849344, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00018549079062292023, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00013877675112009281, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00032728182597354435, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0006709367801937296, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0010080045555079405, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0011829844406791405, shape=(), dtype=float64)\n",
      "tf.Tensor(0.001121446915798474, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0008568568299705411, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005089489004002603, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023241670897219933, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00015532718948204442, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00032264359218857287, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0006671122089044431, shape=(), dtype=float64)\n",
      "tf.Tensor(0.001032035750681415, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0012461664202840681, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0012106839402474408, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009434748407271429, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005628326476881632, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002334934010379635, shape=(), dtype=float64)\n",
      "tf.Tensor(9.908050155012152e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00022024994422516992, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005443499521267305, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00092698021639456, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0012019063282893868, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0012605555474042743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0010917155098961173, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007701704026271666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004189875163178774, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0001661608458984591, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00010182602226506013, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002419739377501835, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005156734688822407, shape=(), dtype=float64)\n",
      "tf.Tensor(0.000795670021773672, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009614215903109555, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0009521977221861583, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0007827027848882443, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005247185706053716, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002714156179079979, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00010213171628444335, shape=(), dtype=float64)\n",
      "tf.Tensor(5.828463101863517e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00013459116447899486, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0002876046038725609, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0004554226794189621, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005776970480069282, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0006119375343717691, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0005460369755074845, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00040378918733847236, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023700423098832653, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00010263455694498428, shape=(), dtype=float64)\n",
      "tf.Tensor(3.716648531590088e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(4.452739532941087e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00010111352381663236, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0001705771679733546, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00021979868589875926, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00023063248884113734, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00020413924692302507, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00015535772437418017, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00010259376298048548, shape=(), dtype=float64)\n",
      "tf.Tensor(5.944431415350848e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(3.285497338024209e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(2.4500776611141578e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(3.191598747226606e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(4.834866428643775e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(6.390886216661304e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(6.99999935675568e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(6.399380470389175e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(4.9790528937344895e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(3.417344335279156e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(2.2397660518139152e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.6102140383446603e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.4044512806670015e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3997548969266836e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.4121217243700274e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.355807617553328e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2566200765831487e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.197123219643579e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2165849724773416e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2740784645295023e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3056964744198406e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.28708001623546e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2328419421395819e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1586976114310903e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.070526614155828e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(9.919090353706421e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(9.731050452500138e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0458428603728218e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1768947825586727e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2863019724575955e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3089617571775865e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.2338903694857305e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0985520655311376e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(9.60182947492099e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(8.7056010341001e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(8.590121325641947e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(9.20035627725857e-06, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0165233976222469e-05, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1024351985475161e-05, shape=(), dtype=float64)\n",
      "[<tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 2.87475262e-02+5.90051530e-18j,  5.28507526e-03+5.55437465e-18j,\n",
      "        -3.35279962e-03+2.44458366e-18j,  6.52948141e-02+4.72490539e-17j],\n",
      "       [ 3.39948809e-01-1.34556572e-16j, -2.60184825e-01+1.60213100e-16j,\n",
      "         2.21479964e-02-8.45542767e-17j, -2.14451787e-03+2.22469337e-17j],\n",
      "       [ 1.34837325e-02+6.90640412e-17j, -2.86779442e-04-5.79082796e-17j,\n",
      "        -1.23354685e-02+3.61416646e-17j, -5.50023412e-02-2.71901950e-17j],\n",
      "       [ 3.54589806e-01-1.59843131e-16j, -3.68067597e-01+5.96661873e-17j,\n",
      "         7.79245670e-03-4.48638669e-17j,  2.79343515e-02+3.70509982e-17j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[-1.86663912e-02-2.07590597e-17j,  4.01334617e-02-1.20014837e-17j,\n",
      "        -9.56201654e-04+2.60692974e-18j,  3.39297424e-03+4.50822079e-19j],\n",
      "       [-4.46876806e-01+1.10497728e-16j,  3.16996995e-01-7.81141899e-17j,\n",
      "         1.34207711e-03+4.97780254e-19j, -2.52166116e-03-1.19577060e-18j],\n",
      "       [-2.54874166e-02+4.39358173e-17j,  4.89151400e-02-5.91946721e-17j,\n",
      "         1.29682218e-04-4.72832534e-18j, -4.15565800e-03+2.88887944e-18j],\n",
      "       [-4.31260801e-01+4.12879294e-17j,  2.55294631e-01-1.24844705e-17j,\n",
      "        -1.79639249e-04+4.72275271e-18j, -1.71312591e-03-3.01019302e-18j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.02460296+3.38113152e-17j,  0.03878343+3.06332090e-17j,\n",
      "        -0.00263383+2.14592565e-17j,  0.22680335-4.71750544e-17j],\n",
      "       [ 0.06455455+1.92150561e-17j, -0.0032156 +8.11670483e-17j,\n",
      "        -0.08831194+4.86373583e-17j, -0.12815786-1.10572536e-16j],\n",
      "       [ 0.01066969+4.78181796e-17j,  0.00278153+6.96517904e-17j,\n",
      "         0.00090611-8.05294743e-19j, -0.21257653+4.71078933e-17j],\n",
      "       [ 0.05725103-7.65373992e-17j, -0.04754745-3.24759350e-17j,\n",
      "        -0.08818153+6.66263100e-17j, -0.02868241-1.92822800e-16j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.3628976 -5.92233282e-18j,  0.4832699 +4.67155140e-17j,\n",
      "         0.44093253-7.62157743e-17j,  0.6091026 +5.48496589e-18j],\n",
      "       [ 0.26665892-4.17789904e-17j,  0.38436212+2.34209158e-17j,\n",
      "        -0.52068601+7.32443147e-18j, -0.08303131+1.43470688e-16j],\n",
      "       [ 0.22679889-8.01082951e-17j,  0.29632248-1.97641438e-17j,\n",
      "         0.56338747-2.61241560e-17j, -0.69234611-1.22435602e-17j],\n",
      "       [-0.32955477-4.10107000e-18j, -0.39276229+1.08950622e-16j,\n",
      "         0.44806135-1.29530103e-16j,  0.14411577-5.15287853e-18j]])>]\n",
      "[0.17783323225306555, 0.09305786270296945, 0.050310479091792634, 0.032338175607970567, 0.024975155813595898, 0.020208018707909663, 0.015199864816154285, 0.010384734742317174, 0.006995008541114377, 0.005480342717166463, 0.005087266526334199, 0.0048865623346148876, 0.004579572056489723, 0.004245657580634725, 0.003947091609232722, 0.003621485302697546, 0.0032214604717145734, 0.0028137271043520745, 0.002482282742984292, 0.002177759684788412, 0.001812442364266464, 0.0014152495602674615, 0.0010931594888187698, 0.0008889216660492382, 0.000789703352234285, 0.0008371150108296539, 0.0010607330473599577, 0.0013134220719874402, 0.0013567640563656586, 0.001120673543963126, 0.0007669977087084954, 0.0005343144429079767, 0.0005675587813332806, 0.0008439861469673014, 0.001187520861400931, 0.0013717765554188315, 0.0012825578002690638, 0.0009865374466680962, 0.000650060988129145, 0.00041817064153379613, 0.0003479493318983939, 0.000409184536811958, 0.0005202777012023018, 0.0005912848244535353, 0.0005708806352095707, 0.0004756755161741914, 0.00036471993024613425, 0.0002835809220029907, 0.00024283222153988657, 0.00023600964599557764, 0.00024945765770773134, 0.0002599766400559823, 0.00025118177827541927, 0.00023203468872861453, 0.00022363187592888383, 0.00023304725551589157, 0.0002488266818258224, 0.0002541308010417205, 0.00023931910142749402, 0.00020960434404991942, 0.00018438065066713196, 0.0001851827546541513, 0.0002203723099770827, 0.00027633156759495145, 0.00032051240571765127, 0.00032050086832423276, 0.0002704202288768113, 0.00020109076156248575, 0.0001624505913442639, 0.0001912366646807776, 0.0002846291953354646, 0.00039801024081015645, 0.00047330399006173616, 0.0004768843672539623, 0.000417038625118048, 0.00033469460438282196, 0.00027930977787385294, 0.0002824754350557848, 0.0003424285369877239, 0.0004300143793803607, 0.000508912453729227, 0.0005503402734773515, 0.0005367861192597353, 0.00046533706639255033, 0.0003546743601785119, 0.00024802476283283917, 0.00020231561849648466, 0.000259966552366367, 0.00041646768461607944, 0.0006109624528040249, 0.0007537828615943203, 0.0007741968993616988, 0.0006576694980265697, 0.00045441133117078497, 0.0002600060725504991, 0.00017597617578431503, 0.00026007159715253484, 0.0004876125507023356, 0.0007539573725378224, 0.0009264433652750285, 0.0009144354706487008, 0.0007160139833137524, 0.00042318721849849344, 0.00018549079062292023, 0.00013877675112009281, 0.00032728182597354435, 0.0006709367801937296, 0.0010080045555079405, 0.0011829844406791405, 0.001121446915798474, 0.0008568568299705411, 0.0005089489004002603, 0.00023241670897219933, 0.00015532718948204442, 0.00032264359218857287, 0.0006671122089044431, 0.001032035750681415, 0.0012461664202840681, 0.0012106839402474408, 0.0009434748407271429, 0.0005628326476881632, 0.0002334934010379635, 9.908050155012152e-05, 0.00022024994422516992, 0.0005443499521267305, 0.00092698021639456, 0.0012019063282893868, 0.0012605555474042743, 0.0010917155098961173, 0.0007701704026271666, 0.0004189875163178774, 0.0001661608458984591, 0.00010182602226506013, 0.0002419739377501835, 0.0005156734688822407, 0.000795670021773672, 0.0009614215903109555, 0.0009521977221861583, 0.0007827027848882443, 0.0005247185706053716, 0.0002714156179079979, 0.00010213171628444335, 5.828463101863517e-05, 0.00013459116447899486, 0.0002876046038725609, 0.0004554226794189621, 0.0005776970480069282, 0.0006119375343717691, 0.0005460369755074845, 0.00040378918733847236, 0.00023700423098832653, 0.00010263455694498428, 3.716648531590088e-05, 4.452739532941087e-05, 0.00010111352381663236, 0.0001705771679733546, 0.00021979868589875926, 0.00023063248884113734, 0.00020413924692302507, 0.00015535772437418017, 0.00010259376298048548, 5.944431415350848e-05, 3.285497338024209e-05, 2.4500776611141578e-05, 3.191598747226606e-05, 4.834866428643775e-05, 6.390886216661304e-05, 6.99999935675568e-05, 6.399380470389175e-05, 4.9790528937344895e-05, 3.417344335279156e-05, 2.2397660518139152e-05, 1.6102140383446603e-05, 1.4044512806670015e-05, 1.3997548969266836e-05, 1.4121217243700274e-05, 1.355807617553328e-05, 1.2566200765831487e-05, 1.197123219643579e-05, 1.2165849724773416e-05, 1.2740784645295023e-05, 1.3056964744198406e-05, 1.28708001623546e-05, 1.2328419421395819e-05, 1.1586976114310903e-05, 1.070526614155828e-05, 9.919090353706421e-06, 9.731050452500138e-06, 1.0458428603728218e-05, 1.1768947825586727e-05, 1.2863019724575955e-05, 1.3089617571775865e-05, 1.2338903694857305e-05, 1.0985520655311376e-05, 9.60182947492099e-06, 8.7056010341001e-06, 8.590121325641947e-06, 9.20035627725857e-06, 1.0165233976222469e-05, 1.1024351985475161e-05]\n"
     ]
    }
   ],
   "source": [
    "kraus_operators_res, cost_dict = optimize_adam_kraus(M_list, rho_list, epsilon, kraus_operators, n, 0.05, num_loop=200)\n",
    "print(kraus_operators_res)\n",
    "print(cost_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_density_matrix(rho):\n",
    "    \"\"\"Ensure rho is Hermitian and positive semi-definite.\"\"\"\n",
    "    rho = (rho + tf.linalg.adjoint(rho)) / 2  # Make it Hermitian\n",
    "    eigvals, eigvecs = tf.linalg.eigh(rho)  # Eigen decomposition\n",
    "    \n",
    "    eigvals = tf.cast(tf.abs(eigvals) + 1e-10, dtype=tf.complex128)  # Convert to complex128\n",
    "    \n",
    "    return eigvecs @ tf.linalg.diag(eigvals) @ tf.linalg.adjoint(eigvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rho_f_i):\n",
      " tf.Tensor(\n",
      "[[ 0.25699585+0.j  0.00137585+0.j -0.00268149+0.j  0.00093819+0.j]\n",
      " [ 0.00137585+0.j  0.25186763+0.j  0.00401742+0.j  0.0105701 +0.j]\n",
      " [-0.00268149+0.j  0.00401742+0.j  0.25728767+0.j -0.01557206+0.j]\n",
      " [ 0.00093819+0.j  0.0105701 +0.j -0.01557206+0.j  0.23384885+0.j]], shape=(4, 4), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "def compute_simulated_data_our_method(kraus_operators, rho_list, epsilon):\n",
    "    \"\"\"Compute rho_f_i = E_rand(sum(K@rho_i@K_dagger))\"\"\"\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for i, rho in enumerate(rho_list):\n",
    "\n",
    "        rho2 = epsilon_rho.calculate_from_kraus_operators(rho, kraus_operators)\n",
    "        data.append(epsilon_rho.calculate_from_unitary_dagger(rho2, epsilon))\n",
    "        \n",
    "    return data \n",
    "\n",
    "# Compute and print the simulated data\n",
    "simulated_data_our_method = compute_simulated_data_our_method(kraus_operators, rho_list, epsilon)\n",
    "rho_list_projected = []\n",
    "for rho in rho_list:\n",
    "    rho_list_projected.append(project_density_matrix(rho))\n",
    "print(\"(rho_f_i):\\n\", simulated_data_our_method[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: tf.Tensor((0.41341797512774225+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def loss_function_our_method(rho_f_list, rho_list):\n",
    "    \"\"\"Compute loss = 1 - mean(Fidelity)\"\"\"\n",
    "\n",
    "    fidelity_sum = tf.constant(0.0, dtype=tf.complex128)\n",
    "\n",
    "    for rho, rho_f in zip(rho_list, rho_f_list):\n",
    "        rho_f = project_density_matrix(rho_f)\n",
    "\n",
    "        sqrt_rho = tf.linalg.sqrtm(rho)\n",
    "        intermediate = sqrt_rho @ rho_f @ sqrt_rho\n",
    "\n",
    "        fidelity = tf.linalg.trace(tf.linalg.sqrtm(intermediate)) ** 2\n",
    "        fidelity_sum += fidelity\n",
    "\n",
    "    fidelity_avg = fidelity_sum / len(rho_list)\n",
    "\n",
    "    return 1 - fidelity_avg  # Loss should approach 0 for perfect matching\n",
    "\n",
    "loss_value = loss_function_our_method(simulated_data,  rho_list_projected)\n",
    "\n",
    "print(\"Loss function value:\", loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize_kraus(kraus_operators):\n",
    "    \"\"\"Ensure Kraus operators satisfy Σ K_i^† K_i = I\"\"\"\n",
    "    summation = sum(tf.linalg.adjoint(K) @ K for K in kraus_operators)\n",
    "    sqrt_inv = tf.linalg.inv(tf.linalg.sqrtm(summation))  # (Σ K_i† K_i)^(-1/2)\n",
    "    return [K @ sqrt_inv for K in kraus_operators]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Hide TensorFlow warnings\n",
    "tf.get_logger().setLevel('ERROR')  # Hide logs\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "def calculate_adam_kraus_our_method(rho_list, unitary, kraus_operators, m, v, num_qubits, t, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, mode = 'fidelity'):\n",
    "    tensorKraus = tf.Variable(kraus_operators, dtype=tf.complex128)\n",
    "    \n",
    "    beta1 = tf.constant(beta1, dtype=tf.complex128)\n",
    "    beta2 = tf.constant(beta2, dtype=tf.complex128)\n",
    "    t = tf.constant(t, dtype=tf.complex128)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        data = compute_simulated_data_our_method(tensorKraus, rho_list, unitary)\n",
    "        f = loss_function_our_method(data, rho_list)\n",
    "\n",
    "    \n",
    "    # Calculate the gradient\n",
    "    c = tape.gradient(f, tensorKraus)\n",
    "    \n",
    "\n",
    "    # Calculate projection\n",
    "    proj = c - tensorKraus @ (np.transpose(np.conjugate(c)) @ tensorKraus + np.transpose(np.conjugate(tensorKraus)) @ c) / 2\n",
    "\n",
    "    # Update Adam variables\n",
    "    m = beta1 * m + (1 - beta1) * proj\n",
    "    v = beta2 * v + (1 - beta2) * tf.math.square(proj)\n",
    "\n",
    "    # Bias correction\n",
    "    m_hat = m / (1 - tf.pow(beta1, t + 1))\n",
    "    v_hat = v / (1 - tf.pow(beta2, t + 1))\n",
    "\n",
    "    # Update the Kraus operators using Adam update rule\n",
    "    updated_kraus_operators = tensorKraus - alpha * m_hat / (tf.math.sqrt(v_hat) + epsilon)\n",
    "    return updated_kraus_operators, m, v, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_adam_kraus_our_method(rho_list, unitary, kraus_operators, num_qubits, alpha=0.001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, num_loop=1000):\n",
    "    kraus_operators_copy = tf.identity(kraus_operators)\n",
    "    \n",
    "    # Initialize m, v to zero matrices\n",
    "    m = tf.zeros_like(kraus_operators_copy, dtype=tf.complex128)\n",
    "    v = tf.zeros_like(kraus_operators_copy, dtype=tf.complex128)\n",
    "    \n",
    "    # Initialize a dictionary to track cost at each iteration\n",
    "    cost_dict = []\n",
    "\n",
    "    # Try looping manually\n",
    "    for i in range(num_loop):\n",
    "\n",
    "        kraus_operators_copy, m, v, cost = calculate_adam_kraus_our_method(rho_list, unitary, kraus_operators_copy, m = m, v = v, num_qubits=num_qubits, t = i, alpha=alpha, beta1=beta1, beta2=beta2, epsilon=epsilon)\n",
    "        print(cost)\n",
    "        \n",
    "        kraus_operators_copy = renormalize_kraus(kraus_operators_copy)\n",
    "        # Store the cost for this iteration\n",
    "        cost_dict.append(cost.numpy().real)\n",
    "        check_kraus_validity(kraus_operators_copy)\n",
    "        # Reshape the matrices\n",
    "        m = tf.reshape(m, (2**num_qubits, 2**num_qubits, 2**num_qubits))\n",
    "        v = tf.reshape(v, (2**num_qubits, 2**num_qubits, 2**num_qubits))\n",
    "\n",
    "    return kraus_operators_copy, cost_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor((0.4134179748917519+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.18100248163697708+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.060828356411600226+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.037458202141911645+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.04374377068674429+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.04175795323982667+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.03358849827923982+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.025819915855206044+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.019471025049422663+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.013644671612046855+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.009060756248809643+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.006806382216344331+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0064593107861783405+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.006267666612341127+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.005193632196932696+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.003726616997811627+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0027667576091641166+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.002403639263241497+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0020972225429898295+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.001617713868931503+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0011899407785550542+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0010081925089883148+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.001001389694976429+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0010529644725332243+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0010772676836077189+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0009809380930820844+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0007503917969035045+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.000521838299850419+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00042408005873229015+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00042928185211998926+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00041952767536479474+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00034423780088510547+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00025973915285371074+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0002254952848981251+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0002310366115634288+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00024122214273369913+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0002437452129167017+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0002213827731277762+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00016453186775244877+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00011001589752879237+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.71663617465035e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.00010729617657112556+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((0.0001013473789739372+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.849839392271019e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.225869270837237e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.8850315592717806e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.647412842457733e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.29127160563414e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.175212503771842e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.7844817814057805e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.068113974020626e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.873862481384993e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.852692788697265e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.378597320824461e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.934539413368409e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.6703277669293257e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.280258414721903e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.0259913927067608e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.073981370342981e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.9552711823522806e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.4992468820751448e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2032129701911032e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2952202187666018e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.3341387803511573e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0861501668402163e-05+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.605448532095217e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.529392479639242e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.21586085966819e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.582701132353598e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.923958872695479e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.2263848730204074e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.629554075265887e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.623080501255707e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.480571661720113e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.488492505227981e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.836050227496891e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.29238792268405e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.982384075535862e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.509222464421647e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.0661643504469325e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.8059303990589655e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.801936388048155e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.71520663244862e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.4385517138080246e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.1281383713333e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.948117449275145e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.892214668870352e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.8457247793767237e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.708322482392056e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.532145560452115e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.3746327406648504e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.2261553446201177e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.1975830536424823e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.196064660897612e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((2.1011615848332e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.9931148305118995e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.9171720553323723e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.8598764478516827e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.8059611317511326e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.7858115951563391e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.7652440376103584e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.6868933239155837e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.6055954207283563e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.577249986173257e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.5874427869988494e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.5440925387188997e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.4499494026543047e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.4076720338263016e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.4137574618766635e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.3907010942837417e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.350926878918024e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.322607129594644e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2909065078003934e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2666538160566176e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2435889154005508e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.2191149040274851e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.1978341429852435e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.1699375005447266e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.1449927589390896e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.1297935371690215e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.1107396142850945e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0859855675837693e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0670991943406705e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0476657362756825e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0267140478914527e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((1.0108341312875524e-06+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.941180127981397e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.743779527671137e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.572116501654904e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.419868116644636e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.269413216994593e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((9.132692672109144e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.975730269034088e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.823446686623271e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.688916243171363e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.562014088830949e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.428427311635289e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.283898791372479e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.151201404960062e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((8.037373091518418e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.924723460783767e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.798178481843721e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.674160323878354e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.563414803346546e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.457887549744413e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.34908911170784e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.240252952733783e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.134113414464238e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((7.032307833831908e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.932840052042977e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.836908598151226e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.740134040894574e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.644453794946159e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.552436998541467e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.462174800825338e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.373901914047408e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.286985306802606e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.200012213630757e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.114987941563399e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((6.032821122659016e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.952613330029166e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.873214434792828e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.795004488495792e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.718363743634214e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.643665758059413e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.569777875580328e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.497008720434238e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.425587412677402e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.355326676559358e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.28657112197628e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.219327585681555e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.153004006830386e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.087552958915609e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((5.023160802863913e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.960003051612816e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.898249803542143e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.837416684999596e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.777411134471166e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.7183754192658967e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.660339167905647e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.6034107770154264e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.5474617649254867e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.492303236069972e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.4380622199469144e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.38465091789908e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.332152703234726e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.280535483847103e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.2296935198748997e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.179642831836361e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.130391446643955e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.081935137678627e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((4.0342687745997807e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.987309971087427e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.941071824442588e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.8955695325082473e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.8507797972542335e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.8066793683899647e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.763228626496584e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.7204446767802324e-07+0j), shape=(), dtype=complex128)\n",
      "tf.Tensor((3.678312529009631e-07+0j), shape=(), dtype=complex128)\n",
      "[<tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.02883275+0.j,  0.02160823+0.j,  0.41984418+0.j,\n",
      "         0.46320615+0.j],\n",
      "       [ 0.19187804+0.j, -0.15561836+0.j, -0.50854789+0.j,\n",
      "        -0.06881144+0.j],\n",
      "       [ 0.02250924+0.j,  0.00892214+0.j,  0.54074412+0.j,\n",
      "        -0.50621741+0.j],\n",
      "       [ 0.16713115+0.j, -0.21373365+0.j,  0.42287166+0.j,\n",
      "         0.11034862+0.j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.02525368+0.j,  0.08973466+0.j, -0.01346635+0.j,\n",
      "         0.1280418 +0.j],\n",
      "       [-0.43522123+0.j,  0.4775947 +0.j,  0.02608649+0.j,\n",
      "        -0.01747959+0.j],\n",
      "       [ 0.00371062+0.j,  0.06688037+0.j, -0.0441562 +0.j,\n",
      "        -0.13543387+0.j],\n",
      "       [-0.53664904+0.j,  0.38478865+0.j, -0.02092829+0.j,\n",
      "         0.02651877+0.j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.14137434+0.j,  0.13226558+0.j,  0.12614111+0.j,\n",
      "         0.45500679+0.j],\n",
      "       [ 0.18788836+0.j,  0.05150651+0.j, -0.13157942+0.j,\n",
      "        -0.107518  +0.j],\n",
      "       [ 0.09039607+0.j,  0.08127617+0.j,  0.17690273+0.j,\n",
      "        -0.5022229 +0.j],\n",
      "       [-0.03297207+0.j, -0.17154364+0.j,  0.15587341+0.j,\n",
      "         0.06803517+0.j]])>, <tf.Tensor: shape=(4, 4), dtype=complex128, numpy=\n",
      "array([[ 0.37776773+0.j,  0.42162628+0.j, -0.0242604 +0.j,\n",
      "        -0.00913625+0.j],\n",
      "       [ 0.28312827+0.j,  0.33263656+0.j,  0.01172509+0.j,\n",
      "         0.0223265 +0.j],\n",
      "       [ 0.23573783+0.j,  0.26354683+0.j,  0.03224745+0.j,\n",
      "         0.01372786+0.j],\n",
      "       [-0.33594796+0.j, -0.35611396+0.j,  0.00734116+0.j,\n",
      "         0.01755079+0.j]])>]\n",
      "[0.4134179748917519, 0.18100248163697708, 0.060828356411600226, 0.037458202141911645, 0.04374377068674429, 0.04175795323982667, 0.03358849827923982, 0.025819915855206044, 0.019471025049422663, 0.013644671612046855, 0.009060756248809643, 0.006806382216344331, 0.0064593107861783405, 0.006267666612341127, 0.005193632196932696, 0.003726616997811627, 0.0027667576091641166, 0.002403639263241497, 0.0020972225429898295, 0.001617713868931503, 0.0011899407785550542, 0.0010081925089883148, 0.001001389694976429, 0.0010529644725332243, 0.0010772676836077189, 0.0009809380930820844, 0.0007503917969035045, 0.000521838299850419, 0.00042408005873229015, 0.00042928185211998926, 0.00041952767536479474, 0.00034423780088510547, 0.00025973915285371074, 0.0002254952848981251, 0.0002310366115634288, 0.00024122214273369913, 0.0002437452129167017, 0.0002213827731277762, 0.00016453186775244877, 0.00011001589752879237, 9.71663617465035e-05, 0.00010729617657112556, 0.0001013473789739372, 7.849839392271019e-05, 6.225869270837237e-05, 5.8850315592717806e-05, 5.647412842457733e-05, 5.29127160563414e-05, 5.175212503771842e-05, 4.7844817814057805e-05, 4.068113974020626e-05, 3.873862481384993e-05, 3.852692788697265e-05, 3.378597320824461e-05, 2.934539413368409e-05, 2.6703277669293257e-05, 2.280258414721903e-05, 2.0259913927067608e-05, 2.073981370342981e-05, 1.9552711823522806e-05, 1.4992468820751448e-05, 1.2032129701911032e-05, 1.2952202187666018e-05, 1.3341387803511573e-05, 1.0861501668402163e-05, 8.605448532095217e-06, 8.529392479639242e-06, 9.21586085966819e-06, 8.582701132353598e-06, 6.923958872695479e-06, 6.2263848730204074e-06, 6.629554075265887e-06, 6.623080501255707e-06, 5.480571661720113e-06, 4.488492505227981e-06, 4.836050227496891e-06, 5.29238792268405e-06, 4.982384075535862e-06, 4.509222464421647e-06, 4.0661643504469325e-06, 3.8059303990589655e-06, 3.801936388048155e-06, 3.71520663244862e-06, 3.4385517138080246e-06, 3.1281383713333e-06, 2.948117449275145e-06, 2.892214668870352e-06, 2.8457247793767237e-06, 2.708322482392056e-06, 2.532145560452115e-06, 2.3746327406648504e-06, 2.2261553446201177e-06, 2.1975830536424823e-06, 2.196064660897612e-06, 2.1011615848332e-06, 1.9931148305118995e-06, 1.9171720553323723e-06, 1.8598764478516827e-06, 1.8059611317511326e-06, 1.7858115951563391e-06, 1.7652440376103584e-06, 1.6868933239155837e-06, 1.6055954207283563e-06, 1.577249986173257e-06, 1.5874427869988494e-06, 1.5440925387188997e-06, 1.4499494026543047e-06, 1.4076720338263016e-06, 1.4137574618766635e-06, 1.3907010942837417e-06, 1.350926878918024e-06, 1.322607129594644e-06, 1.2909065078003934e-06, 1.2666538160566176e-06, 1.2435889154005508e-06, 1.2191149040274851e-06, 1.1978341429852435e-06, 1.1699375005447266e-06, 1.1449927589390896e-06, 1.1297935371690215e-06, 1.1107396142850945e-06, 1.0859855675837693e-06, 1.0670991943406705e-06, 1.0476657362756825e-06, 1.0267140478914527e-06, 1.0108341312875524e-06, 9.941180127981397e-07, 9.743779527671137e-07, 9.572116501654904e-07, 9.419868116644636e-07, 9.269413216994593e-07, 9.132692672109144e-07, 8.975730269034088e-07, 8.823446686623271e-07, 8.688916243171363e-07, 8.562014088830949e-07, 8.428427311635289e-07, 8.283898791372479e-07, 8.151201404960062e-07, 8.037373091518418e-07, 7.924723460783767e-07, 7.798178481843721e-07, 7.674160323878354e-07, 7.563414803346546e-07, 7.457887549744413e-07, 7.34908911170784e-07, 7.240252952733783e-07, 7.134113414464238e-07, 7.032307833831908e-07, 6.932840052042977e-07, 6.836908598151226e-07, 6.740134040894574e-07, 6.644453794946159e-07, 6.552436998541467e-07, 6.462174800825338e-07, 6.373901914047408e-07, 6.286985306802606e-07, 6.200012213630757e-07, 6.114987941563399e-07, 6.032821122659016e-07, 5.952613330029166e-07, 5.873214434792828e-07, 5.795004488495792e-07, 5.718363743634214e-07, 5.643665758059413e-07, 5.569777875580328e-07, 5.497008720434238e-07, 5.425587412677402e-07, 5.355326676559358e-07, 5.28657112197628e-07, 5.219327585681555e-07, 5.153004006830386e-07, 5.087552958915609e-07, 5.023160802863913e-07, 4.960003051612816e-07, 4.898249803542143e-07, 4.837416684999596e-07, 4.777411134471166e-07, 4.7183754192658967e-07, 4.660339167905647e-07, 4.6034107770154264e-07, 4.5474617649254867e-07, 4.492303236069972e-07, 4.4380622199469144e-07, 4.38465091789908e-07, 4.332152703234726e-07, 4.280535483847103e-07, 4.2296935198748997e-07, 4.179642831836361e-07, 4.130391446643955e-07, 4.081935137678627e-07, 4.0342687745997807e-07, 3.987309971087427e-07, 3.941071824442588e-07, 3.8955695325082473e-07, 3.8507797972542335e-07, 3.8066793683899647e-07, 3.763228626496584e-07, 3.7204446767802324e-07, 3.678312529009631e-07]\n"
     ]
    }
   ],
   "source": [
    "kraus_operators_res_our_method, cost_dict_our_method = optimize_adam_kraus_our_method(rho_list_projected, epsilon, kraus_operators, n, alpha=0.1, num_loop=200)\n",
    "print(kraus_operators_res_our_method)\n",
    "print(cost_dict_our_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36428774+0.j  0.22670344+0.j  0.26881254+0.j -0.32852329+0.j]\n",
      " [ 0.22670344+0.j  0.14108201+0.j  0.16728734+0.j -0.20444652+0.j]\n",
      " [ 0.26881254+0.j  0.16728734+0.j  0.19836018+0.j -0.2424215 +0.j]\n",
      " [-0.32852329+0.j -0.20444652+0.j -0.2424215 +0.j  0.29627006+0.j]]\n",
      "Their method: \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0.42156235-1.39629921e-33j  0.26625796+1.64753713e-17j\n",
      "   0.24474124+5.17683314e-17j -0.30055094-3.57646213e-17j]\n",
      " [ 0.26625796-1.64753713e-17j  0.1932767 -6.98149605e-33j\n",
      "   0.15311784+2.25534334e-17j -0.16451771-1.02991671e-17j]\n",
      " [ 0.24474124-5.17683314e-17j  0.15311784-2.25534334e-17j\n",
      "   0.14307857+6.16297582e-33j -0.17703005+1.56894502e-17j]\n",
      " [-0.30055094+3.57646213e-17j -0.16451771+1.02991671e-17j\n",
      "  -0.17703005-1.56894502e-17j  0.24208237-1.08333559e-32j]], shape=(4, 4), dtype=complex128)\n",
      "tf.Tensor((0.9350501756822047-1.0339757656912846e-25j), shape=(), dtype=complex128)\n",
      "Our method: \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0.37308374+0.j  0.27461381+0.j  0.22802612+0.j -0.30679639+0.j]\n",
      " [ 0.27461381+0.j  0.21257714+0.j  0.16973918+0.j -0.22521324+0.j]\n",
      " [ 0.22802612+0.j  0.16973918+0.j  0.14021929+0.j -0.18891732+0.j]\n",
      " [-0.30679639+0.j -0.22521324+0.j -0.18891732+0.j  0.27411984+0.j]], shape=(4, 4), dtype=complex128)\n",
      "tf.Tensor((0.9640857333718493+5.169878828456423e-26j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "rho_test = init.create_random_state(2)\n",
    "\n",
    "rho2 = epsilon_rho.calculate_from_unitary(rho_test, epsilon)\n",
    "\n",
    "rho2_ours = epsilon_rho.calculate_from_kraus_operators(rho_test, kraus_operators_res_our_method)\n",
    "\n",
    "rho2_theirs = epsilon_rho.calculate_from_kraus_operators(rho_test, kraus_operators_res)\n",
    "\n",
    "print (rho2)\n",
    "\n",
    "print (\"Their method: \\n\")\n",
    "print (rho2_theirs)\n",
    "print(metrics.compilation_trace_fidelity(rho2, rho2_theirs))\n",
    "\n",
    "print (\"Our method: \\n\")\n",
    "print (rho2_ours)\n",
    "print(metrics.compilation_trace_fidelity(rho2, rho2_ours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ρ[0]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[1]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[2]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[3]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[4]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[5]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[6]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[7]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[8]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.   0.25 0.25 0.5 ]\n",
      "\n",
      "ρ[9]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.16666667 0.16666667 0.16666667 0.5       ]\n",
      "\n",
      "ρ[10]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[11]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[12]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.   0.25 0.25 0.5 ]\n",
      "\n",
      "ρ[13]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.16666667 0.16666667 0.16666667 0.5       ]\n",
      "\n",
      "ρ[14]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[15]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[16]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[17]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[18]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[19]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[20]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[21]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[22]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.   0.25 0.25 0.5 ]\n",
      "\n",
      "ρ[23]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[24]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[25]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[26]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.16666667 0.16666667 0.16666667 0.5       ]\n",
      "\n",
      "ρ[27]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[28]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[29]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[30]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[31]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.   0.25 0.25 0.5 ]\n",
      "\n",
      "ρ[32]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n",
      "ρ[33]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.16666667 0.16666667 0.16666667 0.5       ]\n",
      "\n",
      "ρ[34]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.16666667 0.16666667 0.16666667 0.5       ]\n",
      "\n",
      "ρ[35]: Hermitian = True, Positive Semi-definite = True, Trace = (1+0j)\n",
      "Eigenvalues: [0.  0.  0.5 0.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_rho_properties(rho_list):\n",
    "    for i, rho in enumerate(rho_list):\n",
    "        is_hermitian = np.allclose(rho, np.transpose(np.conjugate(rho)))  # Check if ρ = ρ†\n",
    "        eigenvalues = np.linalg.eigvalsh(rho)  # Compute eigenvalues\n",
    "        is_positive_semidefinite = np.all(eigenvalues >= -1e-10)  # Allow small numerical errors\n",
    "        trace_one = np.isclose(np.trace(rho), 1)  # Check if Tr(ρ) ≈ 1\n",
    "        \n",
    "        print(f\"ρ[{i}]: Hermitian = {is_hermitian}, Positive Semi-definite = {is_positive_semidefinite}, Trace = {np.trace(rho)}\")\n",
    "        print(f\"Eigenvalues: {eigenvalues}\\n\")\n",
    "\n",
    "check_rho_properties(rho_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def check_kraus_validity(kraus_operators):\n",
    "    \"\"\"Check if sum(K_i^† K_i) = I\"\"\"\n",
    "    dim = kraus_operators[0].shape[0]  # Kích thước của ma trận\n",
    "    identity = tf.eye(dim, dtype=tf.complex128)  # Ma trận đơn vị\n",
    "    summation = sum(tf.linalg.adjoint(K) @ K for K in kraus_operators)  # ∑ K_i^† K_i\n",
    "\n",
    "    # So sánh với ma trận đơn vị\n",
    "    error = tf.linalg.norm(summation - identity).numpy().real\n",
    "    \n",
    "    if np.isclose(error, 0, atol=1e-6):\n",
    "        return\n",
    "    else:\n",
    "        print(\"❌ Invalid Kraus operators! The sum does not equal identity.\")\n",
    "\n",
    "# Kiểm tra\n",
    "check_kraus_validity(kraus_operators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_valid_measurements(M_list, d):\n",
    "    \"\"\"\n",
    "    Kiểm tra xem danh sách các measurement operators M_list có hợp lệ không.\n",
    "    \n",
    "    Điều kiện hợp lệ:\n",
    "    1. M_i phải Hermitian\n",
    "    2. M_i phải Positive Semi-Definite (PSD)\n",
    "    3. Tổng M_i phải bằng ma trận đơn vị I (trong trường hợp POVM)\n",
    "    \n",
    "    Args:\n",
    "        M_list: Danh sách các phép đo\n",
    "        d: Kích thước không gian Hilbert (ví dụ: d=2^n cho hệ n qubit)\n",
    "        \n",
    "    Returns:\n",
    "        None (In kết quả)\n",
    "    \"\"\"\n",
    "    I = np.eye(d)  # Ma trận đơn vị cùng kích thước\n",
    "\n",
    "    completeness_check = np.zeros((d, d), dtype=complex)  # Tổng của các M_i\n",
    "\n",
    "    for i, M in enumerate(M_list):\n",
    "        is_hermitian = np.allclose(M, M.conj().T)  # Kiểm tra Hermitian\n",
    "        eigvals = np.linalg.eigvalsh(M)  # Lấy eigenvalues\n",
    "        is_psd = np.all(eigvals >= -1e-10)  # Kiểm tra PSD (chấp nhận sai số nhỏ)\n",
    "\n",
    "        completeness_check += M  # Cộng vào tổng\n",
    "\n",
    "        print(f\"M[{i}]: Hermitian = {is_hermitian}, Positive Semi-Definite = {is_psd}\")\n",
    "        print(f\"  Eigenvalues: {eigvals}\\n\")\n",
    "\n",
    "    # Kiểm tra tổng M_i có bằng I không (chỉ cần thiết nếu là POVM)\n",
    "    is_complete = np.allclose(completeness_check, I)\n",
    "    print(completeness_check)\n",
    "    print(f\"Completeness Check (ΣM_i = I): {is_complete}\")\n",
    "check_valid_measurements(M_list, 2**n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
